---
layout: default
title: Dat Huynh
custom_css: pub
---

<ul>

<li conference="ECCV20">
	<p>
		E. Elhamifar and <b>D. Huynh</b><br>
		<a href="http://khoury.neu.edu/home/eelhami/publications/SelfSupProcLearn-ECCV2020.pdf">Self-Supervised Multi-Task Procedure Learning from Instructional Videos</a><br>
		<a href="https://github.com/hbdat/eccv20_Multi_Task_Procedure_Learning" style="color:blue;">[Project]</a><br>
		European Conference on Computer Vision, 2020.<br>
	</p>
	
	<p style="margin-top:-5mm;">
	<br><u>Description:</u> Developed a weakly supervised key-frame localization method for multi-task procedure learning in videos
	<br><br>
	<u>Outcome:</u> Applied self-supervised learning on CrossTask and ProceL datasets to localize key-frames without human supervision
	</p>
	
</li>

<li conference="META20">
	<p>
		S. Jafar-Zanjani, M. M. Salary, <b>D. Huynh</b>, E. Elhamifar, and H. Mosallaei<br>
		<a href="">Active Metasurfaces Design by Conditional Generative Adversarial Networks</a><br>
		International Conference on Metamaterials, Photonic Crystals and Plasmonics, 2020.<br>
	</p>
</li>

<li conference="CVPR20">
	<p>
		<b>D. Huynh</b> and E. Elhamifar<br>
		<a href="http://khoury.neu.edu/home/eelhami/publications/MultiAtt-MLZSL-CVPR20.pdf">A Shared Multi-Attention Framework for Multi-Label Zero-Shot Learning</a><br>
		<a href="https://github.com/hbdat/cvpr20_LESA" style="color:blue;">[Project]</a>
		<a href="http://www.ccs.neu.edu/home/eelhami/publications/MultiAtt-MLZSL-CVPR20-suppmat.pdf" style="color:green;">[Supplementary Materials]</a><br>
		IEEE Conference on Computer Vision and Pattern Recognition, 2020.<br>
		<b>Oral Presentation</b><br>
	</p>
	
	<p style="margin-top:-5mm;">
	<br><u>Description:</u> Developed a multi-label recognition system for labels without training samples via attention sharing
	<br><br>
	<u>Outcome:</u> Improved the state-of-the-art performance by 2% mAP score on NUS-WIDE and scaled to 7000 seen labels and 400 unseen labels in Open Images
	</p>
</li>

<li conference="CVPR20">
	<p>
		<b>D. Huynh</b> and E. Elhamifar<br>
		<a href="http://khoury.neu.edu/home/eelhami/publications/FineGrainedZSL-CVPR20.pdf">Fine-Grained Generalized Zero-Shot Learning via Dense Attribute-Based Attention</a><br>
		<a href="https://github.com/hbdat/cvpr20_DAZLE" style="color:blue;">[Project]</a>
		<a href="http://www.ccs.neu.edu/home/eelhami/publications/FineGrainedZSL-CVPR20-suppmat.pdf" style="color:green;">[Supplementary Materials]</a><br>
		IEEE Conference on Computer Vision and Pattern Recognition, 2020.<br>
	</p>
	
	<p style="margin-top:-5mm;">
	<br><u>Description:</u> Developed a dense attribute-based attention mechanism for fine-grained zero-shot learning 
	<br><br>
	<u>Outcome:</u> Improved state-of-the-art performances on CUB, AWA2 by at least 4% harmonic mean by weakly localizing fine-grained attributes of all classes 
	</p>
</li>

<li conference="CVPR20">
	<p>
		<b>D. Huynh</b> and E. Elhamifar<br>
		<a href="http://khoury.neu.edu/home/eelhami/publications/InteractiveCMLL-CVPR20.pdf">Interactive Multi-Label CNN Learning with Partial Labels</a><br>
		<a href="https://github.com/hbdat/cvpr20_IMCL" style="color:blue;">[Project]</a>
		<a href="http://www.ccs.neu.edu/home/eelhami/publications/InteractiveCMLL-CVPR20-suppmat.pdf" style="color:green;">[Supplementary Materials]</a><br>
		IEEE Conference on Computer Vision and Pattern Recognition, 2020.<br>
	</p>
	
	<p style="margin-top:-5mm;">
	<br><u>Description:</u> Developed a scalable framework for multi-label CNN training with missing labels
	<br><br>
	<u>Outcome:</u> Improved 2% mAP score on Open Images compared to treating missing labels as absent labels
	</p>
</li>

<li conference="ICCVW19">
	<p>
		<b>D. Huynh</b> and E. Elhamifar<br>
		<a href="http://www.lsfsl.net/ws/ea/ICCV2019_MDALC_EA07.pdf">Seeing Many Unseen Labels via Shared Multi-Attention Models</a><br>
		International Conference on Computer Vision Workshop, 2019<br>
		Workshop on Multi-Discipline Approach for Learning Concepts - Zero-Shot, One-Shot, Few-Shot and Beyond.
	</p>
</li>
</ul>